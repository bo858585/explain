# Осваивая EXPLAIN

***Наброски перевода***

###1. Лицензия на слайды
- Creative Common BY-NC-SA
- You are free
  - to Share
  - to Remix
- Under the following conditions
  - Attribution
  - Noncommercial
  - Share Alike

###2. Автор
- Guillaume Lelarge
- Work
  - CTO of Dalibo
  - email: guillaume.lelarge@dalibo.com
- Community
  - pgAdmin, the french documentation, pgconf.eu organization, vice-treasurer
of PostgreSQL Europe, etc.
  - email: guillaume@lelarge.info
  - twitter: @g_lelarge

###3. Осваивая EXPLAIN
- EXPLAIN - немного жутковатая команда
- Но Вам нужно только несколько подсказок, чтобы понять, как она работает
- Об этом здесь и пойдет речь
  - понимайте
  - используйте
  - и полюбите ее

EXPLAIN - очень симпатичная команда, которая может выдать вам много информации, но зачастую непросто понять, что же делать со всей этой информацией. Это довольно досадно, потому что есть не так уж и много вещей, которые о ней нужно знать. Обо всем этом здесь пойдет речь - будет рассказано о том, как правильно интерпретировать информацию, выдаваемую этой командой, как использовать эту информацию, и исправлять ваши запросы так, чтобы они работали быстрее.

###4. Во-первых, создадим объекты
Создайте их.

```sql
$ CREATE TABLE foo (c1 integer, c2 text);
$ INSERT INTO foo
$     SELECT i, md5(random()::text)
$     FROM generate_series(1, 1000000) AS i;
```

При помощи этих двух запросов создается таблица и заполняется случайными числами. Эта таблица будет основой наших примеров.

###5. Давайте попробуем запросить из таблицы данные
```sql
$ EXPLAIN SELECT * FROM foo;
$                 QUERY PLAN
$ .....................................
$ Seq Scan on foo  (cost=0.00..18584.82
$                   rows=1025082 width=36)
```

- Cost
  - стоимость получения первой строки: 0.00
  - стоимость получения всех строк: 18584.82
  - единицы измерения стоимости - “в страницах памяти”
- Rows
  - число выданных строк
- Width
  - Cреднее средних длин записей разных столбцов (подробнее см. ниже - прим. пер.)
  - в байтах

В PostgreSQL таблицу можно читать многими способами. Наиболее простой способ - читать таблицу последовательно, блок за блоком.

В плане выполнения это отражено. У вас также есть некоторая статистическая информация, предоставляемая планировщиком.

Первое число из диапазона cost - стоимость получения первой строки таблицы. Второе число - стоимость получения всех строк в результате последовательного сканирования таблицы. Помните, что эта стоимость измеряется не во временных единицах, а в страницах памяти. То есть, стоимость считывания одной страницы по умолчанию равна 1.0.

Число строк rows это число строк таблицы, которое планировщик ожидает получить при
последовательном сканировании.

Width - Cумма средних длин записей столбцов результирующей выборки (подробнее см. ниже).

Нужно добавить, что число строк rows только приблизительно равно числу строк, считанному реально. Отличия небольшие, но они могут возникнуть, например, при одновременной работе Autovacuum Daemon и вставок (INSERT’s) в таблицу.

###6. Обновим статистику по таблице

```sql
$ ANALYZE foo;
$ EXPLAIN SELECT * FROM foo;
$                 QUERY PLAN
$ ........................................
$ Seq Scan on foo  (cost=0.00..18334.00
$                   rows=1000000 width=37)
```

- Теперь количество строк верное.
- Но как же считается статистика?

Нам необходимо обновить статистику по таблице и для этого мы вызываем команду ANALYZE. Если необходима статистика только по одной таблице foo, указывается ее название, но это необязательно.

Если после завершения ANALYZE попробовать выполнить команду EXPLAIN, статистика в планировщике уже будет обновлена. Количество строк rows верное, сумма средних длин записей столбцов выборки width стала немного больше, а страничная стоимость cost несколько ниже (стоимость зависит от количества строк, от суммы средних длин записей столбцов width она не зависит (?)).

Все это понятно, но как вся эта информация высчитывается? Почему ANALYZE важна здесь?

###7. Что делает ANALYZE?
- Считывает некоторое количество случайных строк таблицы.
  - это число равно 300*default_statistics_target
- Вычисляет некоторую статистику по значениям из каждого столбца таблицы в этих строках.
- Считает некоторые общие статистические параметры, гистограмму на их основе
  - парамаетры зависят от default_statistics_target
  - могут быть настроены для каждого столбца
-  Сохраняет статистику по столбцам в каталоге pg_statistic
- Посмотрите pg_stats view
  - прост для чтения
  - много довольно интересной информации

ANALYZE читает указанную часть каждой таблицы из базы данных (если вы укажете конкретную таблицу, он будет читать только ее). Выборка из таблицы производится случайным образом. Ее размер зависит от значения параметра default_statistics_target - в 300 раз больше этого значения. По умолчанию, default_statistics_target равен 100 (с версии 8.4), так что будут считаны 30к случайных строк таблицы.

Вся статистическая информация хранится в системном каталоге pg_statistic. Его довольно трудно читать, для удобства есть симпатичный pg_stats view. Мы увидим некоторые из его столбцов дальше по тексту.

Сейчас разберемся, как планировщик вычисляет статистическую информацию (под чертой), выданную в EXPLAIN.

###8. Width
```sql
$ SELECT sum(avg_width) AS width
$ FROM pg_stats
$ WHERE tablename='foo';
$ width  
$ -----
$    37
```

 - (avg_width - из стандартной документации "средняя длина в байтах записей столбца" — прим. пер. http://www.postgresql.org/docs/8.4/static/view-pg-stats.html  )
Width - сумма по всем столбцам средних длин записей столбцов результирующей выборки.
 - The lesser, the better

Width -  это сумма средних длин ячеек каждого столбца. Так как ANALYZE вычисляет среднюю длину полученных ячеек, принадлежащих каждому столбцу результирующей таблицы, то мы можем получить эту информацию путем суммирования этих значений для каждого столбца таблицы. SQL-запрос в примере выше считает эту сумму.

###9. Rows

```sql
$ SELECT reltuples FROM pg_class WHERE relname='foo';
$ reltuples
$ ---------
$ 1e+06
```
- Все метаданные отношений хранятся в каталоге pg_class
- Много интересной информации
  - reltuples
  - relpages
  - relallvisible

Количество строк легко получить. Системный каталог pg_class это каталог всех отношений (таблиц, индексов, последовательностей, и т.д.) в базе данных. Этот каталог содержит метаданные об отношениях. Он также содержит некоторую статистическую информацию, такую как предполагаемое число строк (колонка  reltuples), предполагаемое число файловых страниц (relpages). И число страниц, содержащих только видимые строки для всех текущих транзакций (relallvisible).(?)

На сей раз нас интересует reltuples.

###10. Общая стоимость

- При последовательном канировании исполнитель должен
  - прочитать все блоки отношения foo
  - проверить каждую строку каждого блока для фильтрации "незаметных" (невыводимых?) строк

Общую стоимость вычислить немного сложнее. Когда PostgreSQL делает последовательный скан, она в основном делает две вещи. Во-первых, она должна прочитать все блоки (страницы) памяти таблицы. Для каждого блока она должна найти и проверить каждую строку. То есть у каждого блока есть своя стоимость считывания. В файле postgresql.conf существует параметр seq_page_cost, который указывает на стоимость последовательного считывания одной страницы (блока) памяти. Стоимость cчитывания всех блоков таблицы определяется этим параметром seq_page_cost, умноженном на число блоков этого отношения (relpages в pg_class). Затем для того, чтобы проверить ("отфильтровать" - прим. пер.) каждую строку таблицы, в файле postgresql.conf существует соответсвующий параметр стоимости проверки строки. Все, что Postgres нужно сделать, это умножить эту стоимость на количество строк таблицы (reltuples в pg_class). А затем сложить эти две стоимости, и все готово. Так что все в порядке и мы теперь знаем, как планировщик вычисляет выведенные этим запросом числа.

###11. Но что происходит реально?

Давайте будем использовать опцию ANALYZE для выяснения.

```sql
$ EXPLAIN (ANALYZE) SELECT * FROM foo;
$                           QUERY PLAN
$ ------------------------------------
$ Seq Scan on foo(cost=0.00..18334.00
$                 rows=1000000
$                 width=37)
$                 (actual time=0.016..96.074
$                 rows=1000000
$                 loops=1)
$ Total runtime: 132.573 ms
```

- 3 новых параметра
  - реальное время выполнения в миллисекундах
  - реальное число строк
  - число циклов
- Будьте осторожны, запрос выполняется реально!

Но, может быть, вы хотите знать, что происходит на самом деле, когда вы выполняете запрос. Получить фактическое время выполнения и фактическое количество строк как правило лучше. Мы можем сделать это, добавив опцию ANALYZE в  команду EXPLAIN. Обратите внимание на круглые скобки вокруг этой опции. Это новый способ добавления опций в команду EXPLAIN. Новый с версии 9.0.

Время выполнения запроса для получения первой строки, время выполнения запроса для получения всех строк, общее число строк, число циклов. О цикле сейчас мы говорить не будем. Время выполнения выводится в миллисекундах, так что последовательное сканирование здесь будет идти 96мс и вынимать из таблицы 1 миллион строк. Предполагаемое число строк было верным.

Будьте осторожны при использовании опции ANALYZE в сочетанни с любой DML командой. EXPLAIN ANALYZE
UPDATE… действительно обновит строки таблицы. То же самое касается DELETE или INSERT. Поместите их явно в отдельную транзакцию, чтобы иметь возможность выполнить ROLLBACK.

###12. А на физическом уровне?

- Во-первых, давайте сбросим все кэши.

```sql
$ /etc/init.d/postgresql stop
$ sync
$ echo 3 > /proc/sys/vm/drop_caches
$ /etc/init.d/postgresql start
```

А сейчас давайте посмотрим, что происходит на физическом уровне.

###13 Давайте использовать опцию BUFFERS

```sql
$ EXPLAIN (ANALYZE,BUFFERS) SELECT * FROM foo;
$                           QUERY PLAN
$ --------------------------------------------
­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­$ Seq Scan on foo  (cost=0.00..18334.00
$                   rows=1000000 width=37)
$                  (actual time=14.638..507.726
$                   rows=1000000 loops=1)
$     Buffers: shared read=8334
$ Total runtime: 638.084 ms
```

- BUFFERS добавлена в версии 9.0
- Новая информация
 - число блоков, прочитанных и записанных
 - в кэше PostgreSQL (hit)
 - и вне (прочитано)

 Мы будем использовать другой вариант команды EXPLAIN. Эта опция, называемая BUFFERS, доступна
 с момента выпуска 9.0. Она добавляет некоторую новую информацию, связанную с буферами: буферы, прочитанные кэшем PostgreSQL; буферы, прочитанные Linux, записанные буферы, буферы для временных объектов, etc.

В этом примере "shared read" это число блоков, прочитанных вне PostgreSQL. Эта цифра имеет смысл, если мы только что запустили PostgreSQL и кэш пока что пуст. PostgreSQL должна получить доступ к 8334 блокам памяти для чтения всей таблицы.

###14 Попробуем с прогретым кэшем?

```sql
$ EXPLAIN (ANALYZE,BUFFERS) SELECT * FROM foo;
$                  QUERY PLAN                                                   
­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­
$ Seq Scan on foo (cost=0.00..18334.00
$                  rows=1000000 width=37)
$                 (actual time=0.046..115.908
$                  rows=1000000 loops=1)
$   Buffers: shared hit=32 read=8302
$ Total runtime: 171.803 ms
$ SELECT current_setting('shared_buffers') AS shared_buffers,
$        pg_size_pretty(pg_table_size('foo')) AS table_size;
$ shared_buffers | table_size
$ ­­­­­­­---------------­­­­­­­­­+­­­­­­­­­­­­------------
$ 32MB           | 65 MB
```

Давайте выполним запрос во второй раз, теперь, когда кэш уже разогрет. Мы обнаружим, что читаем 32 блока из кэша PostgreSQL и 8302 за пределами кэша PostgreSQL. Много некэшируемых данных.

Одна из причин, по которой такое происходит, состоит в том, что наша таблица больше, чем кэш-память.
Размер нашей таблицы 65MB, более чем в два раза больше кэша PostgreSQL. Но настоящая причина в том, что PostgreSQL использует кольцевой буфер оптимизации. Это означает, что SELECT не может использовать весь кэш только для себя. То же самое происходит с опцией VACUUM. Он пытается мирно сосуществовать с другими потенциальными сессиями. С большим кэшем мы будем иметь то же самое поведение, но большая часть таблицы будет иметь возможность остаться в кэше. Обратите внимание, что запрос в три раза быстрее, чем с пустым кэшем. Наличие большого свободного дискового кэша Linux действительно помогает.

###15 Давайте попробуем с кэшем большего размера
- с shared_buffers, равным 320MB

```sql
$ EXPLAIN (ANALYZE,BUFFERS) SELECT * FROM foo;
$               QUERY PLAN
­­$ ­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­--------------------------------------------
­­$ ­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­Seq Scan on foo  (cost=0.00..18334.00
$                   rows=1000000 width=37)
$                  (actual time=15.009..532.372
$                   rows=1000000 loops=1)
$   Buffers: shared read=8334
$   Total runtime: 646.289 ms
$
$ EXPLAIN (ANALYZE,BUFFERS) SELECT * FROM foo;
$               QUERY PLAN
­­$ ­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­--------------------------------------------
$ Seq Scan on foo (cost=0.00..18334.00
$                  rows=1000000 width=37)
$                 (actual time=0.014..100.762
$                  rows=1000000 loops=1)
$   Buffers: shared hit=8334
$   Total runtime: 147.999 ms
```

Поместим 320MB в кэш PostgreSQL. Очистим кэш Linux перед перезапуском PostgreSQL. При выполнении первого запроса вся таблица читается с диска, и запрос выполняется 646мс. Во втором запросе все уже в кэше Postgresql (только shared hits), и запрос выполняется 147мс.

###16 К слову
Если вы хотите больше узнать о буферном кэше
- go see Bruce Momjian's talk
- “Inside PostgreSQL Shared Memory”
- Tomorrow, 1:40pm to 2:30pm
- Room Seine

###17 Теперь давайте попробуем команду WHERE

```sql
$ EXPLAIN SELECT * FROM foo WHERE c1 > 500;
$                QUERY PLAN                          
­­$ ­­­­­­­­­­­­­-----------------------------------------­­­­­­­­­­­­­­­­­­­­­­­­­­
$ Seq Scan on foo (cost=0.00..20834.00
$                  rows=999579 width=37)
$    Filter: (c1 > 500)
```

- Новая строчка: Filter: (c1 > 500)
- Стоимость выше
  - Меньше строк
  - Но больше работы из-за присутствия фильтра
- Число строк не до конца верное, но приемлемое

На этот раз, мы используем команду WHERE. У нас нет индекса в этой колонке (и вообще нет индексов таблице) и поэтому единственный способ это сделать - последовательное сканирование таблицы. Во время чтения каждого блока и проверки видимости каждой строки PostgreSQL проверит, что c1 > 500. Если это не так, строчка пропускается. Это суть новой строки с командой Filter.

Даже если мы заканчиваем с меньшим числом строк, у нас все равно больше работы, потому что мы должны проверить значение столбца c1 для каждой строки таблицы. Таким образом, ожидаемая общая стоимость будет больше, чем запрос без фильтра.

Как вы можете видеть, ожидаемое число строк неточно, но, тем не менее, близко к действительному значению.

###18 Cost - более сложный процесс
Исполнитель
 - читает все блоки отношения foo
 - фильтрует строки согласно команде WHERE
 - проверяет оставшиеся строки, чтобы убедиться, что они видимы

```sql
$ SELECT
$   relpages*current_setting('seq_page_cost')::float4
$ + reltuples*current_setting('cpu_tuple_cost')::float4
$ + reltuples*current_setting('cpu_operator_cost')::float4
$   AS total_cost
$ FROM pg_class
$ WHERE relname='foo';
$ total_cost 
­­-------------
        20834
```

Тут немного сложнее рассчитать стоимость. Когда PostgreSQL нужно выполнить этот запрос, ей нужно прочитать все блоки таблицы. Таким образом, у нас по-прежнему есть стоимость чтения в такой формулировке: число блоков, умноженное на стоимость последовательного сканирования таблицы. PostgreSQL также все еще нуждается в проверке видимости каждой строки, и формула, приведенная выше по тексту и здесь также применима: число строк таблицы, умноженное на cpu_tuple_cost. Разница состоит лишь в фильтре: мы должны использовать оператор в колонке с условием для каждой строки. У нас также есть параметр, который дает стоимость использования этого оператора (с именем cpu_operator_cost). Мы будем использовать этот оператор в каждой строке, так что получаем эту третью новую формулу: число кортежей, умноженное на cpu_operator_cost.

Добавим это третье слагаемое и мы получаем общую стоимость запроса.

###19 Число строк - то же самое

```sql
$ SELECT histogram_bounds 
$ FROM pg_stats
$ WHERE tablename='foo' AND attname='c1';
$                        histogram_bounds
# -----------------------------------------------------------
­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­$ {57,10590,19725,30449,39956,50167,59505,...,999931}
$
$ SELECT round(
$ (
$     (10590.0­500)/(10590­57)
$     +
$     (current_setting('default_statistics_target')::int4 ­ 1)
$ )
$  * 10000.0
$ ) AS rows;
$   rows       ­­­­­­­­­
$ 999579
```

По оценкам, ожидаемое число строк является еще более сложным.
PostgreSQL использует гистограмму значений, чтобы получить ожидаемую оценку числа строк. Эта гистограмма разделена на 100 частей, содержащих такое же количество строк. 100 - значение по умолчанию для default_statistics_target. Таблица содержит 1000000 строк, поэтому каждая часть будет иметь 10 000 строк.
Первая часть имеет значения между 57 и 10590. Так как мы ищем значения после 500, это означает, что мы будем иметь только процент от этой части, а все остальные части полностью. Формулы на слайде отражают это, и дают число строк, ожидаемых планировщиком.(?)

###20 Поможет ли здесь индекс?

```sql
$ CREATE INDEX ON foo(c1);
$ EXPLAIN SELECT * FROM foo WHERE c1 > 500;
$                QUERY PLAN
­­$ ­­­­­­­­­­­­­------------------------------------------­­­­­­­­­­­­­­­­­­­­­­­­­­
$ Seq Scan on foo  (cost=0.00..20834.00
$                   rows=999529 width=37)
$   Filter: (c1 > 500)
```

- Нет

Как правило, все думают, что индекс поможет выполнить запрос быстрее, если в запросе есть команда WHERE. В нашем случае это не так. Помните, что это таблица 1000000 строк, и мы пропускаем только 500 строк. Это гораздо лучше сделать фильтр с использованием процессора, чем использовать индекс.

###21 Почему не использовать индекс?

```sql
$ EXPLAIN (ANALYZE) SELECT * FROM foo WHERE c1 > 500;
$                    QUERY PLAN
­­$ ­­­­­­­­­­­­­­­­­----------------------------------------------------­­­­­­­­­­­­­­­­­­­­­­­­­­­­
$ Seq Scan on foo  (cost=0.00..20834.00
$                   rows=999493 width=37)
$                  (actual time=0.125..147.613
$                   rows=999500 loops=1)
$   Filter: (c1 > 500)
$   Rows Removed by Filter: 500
$   Total runtime: 184.901 ms
```

- Новая строчка: Rows Removed by Filter: 500
  - Отображается только с опцией ANALYZE
  - с версии 9.2
- Необходимо прочитать 99.95% таблицы!


Если у вас нет каких-либо знаний о таблице, релиз 9.2 поможет вам немного больше. Давайте попробуем EXPLAIN ANALYZE в таблице Foo в версии 9.2. Обратите внимание на новую строку "Rows Removed by Filter". 500 строк удалены с помощью фильтра, и мы заканчиваем с 999 500 строками в результирующей выборке. Необходимо прочитать 99,95% таблицы! В этом случае индекс никогда не будет использоваться.

###22 Давайте попробуем принудительно использовать индекс

```sql
$ SET enable_seqscan TO off;
$ EXPLAIN (ANALYZE) SELECT * FROM foo WHERE c1 > 500;
$ SET enable_seqscan TO on;
$                    QUERY PLAN
­­$ ­­­­­­­­­­­­­­­­­----------------------------------------------------­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­
$ Index Scan using foo_c1_idx on foo
$   (cost=0.00..36801.25 rows=999480 width=37)
$   (actual time=0.099..186.982 rows=999500 loops=1)
$   Index Cond: (c1 > 500)
$ Total runtime: 221.354 ms
$ (3 rows)
```

- Работает, но медленно
- Планировщик был прав
  - Индекс здесь роли не играет


Чтобы убедиться, что стоимость здесь действительно больше, давайте попробуем заставить планировщик использовать индекс при сканировании. Для этого у нас есть параметры вида “enable_*”. Тот, который нам нужен, называется enable_seqscan, установим его значение off. Помните, что это не отключит полностью последовательное сканирование (если у вас нет индекса, то не существует другого пути, кроме как последовательное сканирование), но это сделает более сложным использование последовательного сканирования (добавлением действительно впечатляющей стоимости к этому специфическому виду узла).

Значит, когда мы устанавливаем enable_seqscan off, индекс будет использоваться. Но вы можете видеть, что использование индекса занимает немного больше времени (221ms), чем чтение всей таблицы и ее фильтрация (184ms).

###23 Давайте посмотрим на примере другого запроса

```sql
$ EXPLAIN SELECT * FROM foo WHERE c1 < 500;
$                QUERY PLAN
­­$ ­­­­­­­­­­­­­------------------------------------------­­­­­­­­­­­­­­­­­­­­­­­­­­
$ Index Scan using foo_c1_idx on foo
$   (cost=0.00..24.59 rows=471 width=37)
$   Index Cond: (c1 < 500)
```

- Новая строчка: Index Cond: (c1 < 500)
- Таблица все еще читаеся для получения информации о видимости строк

Давайте теперь изменим фильтр. На этот раз у нас есть индексное сканирование. У нас есть такой вид узла(?), так как мы читаем небольшое число строк (только 499 из 1 миллиона).

###24 Давайте усложним фильтр

```sql
$ EXPLAIN SELECT * FROM foo
$         WHERE c1 < 500 AND c2 LIKE 'abcd%';
$                QUERY PLAN
­­$ ­­­­­­­­­­­­­--------------------------------------------­­­­­­­­­­­­­­­­­­­­­­­­­
$ Index Scan using foo_c1_idx on foo
$   (cost=0.00..25.77 rows=71 width=37)
$   Index Cond: (c1 < 500)
$   Filter: (c2 ~~ 'abcd%'::text)
```

- “Index Cond”, и “Filter”

А теперь давайте добавим другой фильтр. Так что, мы в конечном итоге просматриваем индекс по столбцу c1 и фильтруем считанные из таблицы строки, чтобы получить только те строки, которые имеют "ABCD" в начале колонки С2.

###25 Давайте попробуем фильтровать только по c2

```sql
$ EXPLAIN (ANALYZE)
$ SELECT * FROM foo WHERE c2 LIKE 'abcd%';
$                   QUERY PLAN
­­$ ----------------------------------------- ­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­
$ Seq Scan on foo  (cost=0.00..20834.00
$                   rows=100 width=37)
$                  (actual time=21.435..134.153
$                   rows=15 loops=1)
$    Filter: (c2 ~~ 'abcd%'::text)
$    Rows Removed by Filter: 999985
$    Total runtime: 134.198 ms
```

- 999985 строк удалено фильтром
- Только 15 строк в результате
- Таким образом, индекс здесь, безусловно, помогает

Здесь мы фильтровали только по С2. У нас нет индекса в c2, поэтому PostgreSQL делает последовательное сканирование. Можно заметить, что последовательное сканирование читает миллионов строк (999985 + 15), и оставляет из них только 15. Индекс по С2, безусловно, поможет.

###26 Давайте добавим индекс в c2

```sql
$ CREATE INDEX ON foo(c2);
$ EXPLAIN (ANALYZE) SELECT * FROM foo
$ WHERE c2 LIKE 'abcd%';
$                  QUERY PLAN
$ ­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­--------------------------------------
$ Seq Scan on foo (cost=0.00..20834.00
$                  rows=100 width=37)
$                 (actual time=22.189..143.467
$                  rows=15 loops=1)
$   Filter: (c2 ~~ 'abcd%'::text)
$   Rows Removed by Filter: 999985
$ Total runtime: 143.512 ms
```

- Это не работает!
- Кодировка UTF8...
  - Мы вынуждены использовать операторный класс.

Итак, давайте добавим индекс в с2. После того, как мы выполняем EXPLAIN, мы видим, что у нас используется последовательное сканирование. Индекс не используется при выполнении запроса. Это странно.

Проблема здесь в том, что индекс не подходит. В столбце c2 значения сохранены в кодировке UTF8.
При использовании кодировки, отличной от С(?), при создании индекса необходимо определять операторный класс (varchar_pattern_ops, text_pattern_ops и т.д.).

###27 Давайте добавим индекс с операторным классом.

```sql
$ CREATE INDEX ON foo(c2 text_pattern_ops);
$ EXPLAIN SELECT * FROM foo WHERE c2 LIKE 'abcd%';
$                    QUERY PLAN
­­$ ­­­­­­­­­­­­­­­­­-------------------------------------------------­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­
$ Bitmap Heap Scan on foo (cost=7.29..57.91
$                          rows=100 width=37)
$   Filter: (c2 ~~ 'abcd%'::text)
$   -­>  Bitmap Index Scan on foo_c2_idx1
$         (cost=0.00..7.26 rows=13 width=0)
$         Index Cond: ((c2 ~>=~ 'abcd'::text)
$                      AND (c2 ~<~ 'abce'::text))
```

- Новый тип узла: Bitmap Index Scan (?)

Раз есть индекс с подходящим операторным классом, планировщик может использовать индекс, чтобы сделать выполнение запроса быстрее.

Обратите внимание на новый вид сканируемого узла. Bitmap Index Scan это еще один способ использовать индекс. И есть еще один в версии 9.2.

###28 Давайте попробуем покрывающий индекс

```sql
$ EXPLAIN SELECT c1 FROM foo WHERE c1 < 500;
­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­$                  QUERY PLAN
$ -------------------------------------------
$ Index Only Scan using foo_c1_idx on foo
$   (cost=0.00..26.40 rows=517 width=4)
$   Index Cond: (c1 < 500)
```

- в версии 9.2
- Не читает биты видимости непосредственно в таблице

В некоторых запросах все дополнительные сведения, хранящиеся в индексе, являются единственной информацией, необходимой для ответа на запрос. Приведенный выше запрос является прекрасным примером. В индексе foo_c1_idx содержится значение столбца c1, так что он может быть использован для фильтрации и получения значений результирующего набора.
Обычно в таких случаях используется термин "покрывающий индекс"

Узлы вида “Index Only Scan” используются, когда доступен покрывающий индекс. Это быстрее, чем
обычный "Index Scan", потому что не нужно читать таблицу, чтобы узнать, видна строка или нет.

Реализовано в версии 9.2.

###29 Все основные узлы сканирования
- Последовательное сканирование
  - читает всю таблицу в последовательном порядке
- Индексное сканирование
  - читает индекс для фильтрации по команде WHERE
  - и таблицу для фильтрации "невидимых" (фильтруемых? не поподающих в выборку) строк
- Bitmap Index Scan (битовая карта)
  - такой же
  - но читает весь индекс, а затем таблицу
  - намного более быстрый для большого числа строк
- Index Only Scan
  - для покрывающего индекса

Таким образом, мы видели все основные узлы сканирования: последовательное сканирование, сканирование индекса, сканирование битового индекса, сканирование только индекса. Все они интересны и полезны для ответов на разные виды запросов.

Есть другие способы сканирования, такие как function scan or the values scan, но у нас нет времени обсуждать их во время этой беседы.

###30 Давайте попробуем команду ORDER BY

```sql
$ DROP INDEX foo_c1_idx;
$ EXPLAIN (ANALYZE) SELECT * FROM foo ORDER BY c1;
$ QUERY PLAN
­­$ ­­­­­­­­----------------------------------------------------­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­
$ Sort
$   (cost=172682.84..175182.84 rows=1000000 width=37)
$   (actual time=612.793..729.135 rows=1000000 loops=1)
$   Sort Key: c1
$   Sort Method: external sort  Disk: 45952kB
$ ­  ->  Seq Scan on foo  (cost=0.00..18334.00
$                         rows=1000000 width=37)
$                        (actual time=0.017..111.068
$                         rows=1000000 loops=1)
$ Total runtime: 772.685 ms
```

Существует много способов ответить на коменду "ORDER BY" (или делать сортировку для нее). Простейший (или тот, который не предполагает других объектов, чем таблицы) - сортировать процессором при выполнении запроса. Это займет процессорное время и память. В этом примере, необходимо так много памяти, что PostgreSQL сортирует на диске. Используется 45MB. Так как на диск пишется много данных, это занимает много времени. Для выполнения последовательного сканирования требуется гораздо меньше времени (111ms), чем
время для выполнения сортировки (618мс = 729мс-111мс).

Это также первый раз, когда у нас есть двухузловой план. Первый тип узла выполняется при последовательном сканировании, второй - при сортировке. Заметьте также, что мы имеем больше информации: ключ сортировки и метод сортировки.

### Есть ли уверенность, что происходит запись на диск?

```sql
$ EXPLAIN (ANALYZE,BUFFERS) SELECT * FROM foo ORDER BY c1;
$                         QUERY PLAN
­­$ ­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­---------------------------------------------------------
$ Sort
$   (cost=172682.84..175182.84 rows=1000000 width=37)
$   (actual time=632.796..756.958 rows=1000000 loops=1)
$   Sort Key: c1
$   Sort Method: external sort  Disk: 45952kB
$   Buffers: shared hit=3910 read=4424,
$            temp read=5744 written=5744
$   -­>  Seq Scan on foo  (cost=0.00..18334.00
$                         rows=1000000 width=37)
$                        (actual time=0.134..110.617
$                         rows=1000000 loops=1)
$          Buffers: shared hit=3910 read=4424
$ Total runtime: 811.308 ms
```

Чтобы убедиться, что PostgreSQL действительно пишет на диск временные данные для сортировки, мы можем использовать опцию BUFFERS команды EXPLAIN. Интересная строка здесь “temp read=5744 written=5744”. PostgreSQL пишет 5744 временных данных, и читает их. 5744 блоков по 8KB это ожидаемые 45MB.

###32 Давайте выделим больше памяти для сортировки

```sql
$ SET work_mem TO '200MB';
$ EXPLAIN (ANALYZE) SELECT * FROM foo ORDER BY c1;
$                       QUERY PLAN
$ ---------------------------------------------------
­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­$ Sort
$   (cost=117991.84..120491.84 rows=1000000 width=37)
$   (actual time=552.401..598.984 rows=1000000 loops=1)
$   Sort Key: c1
$   Sort Method: quicksort  Memory: 102702kB
$   -­>  Seq Scan on foo  (cost=0.00..18334.00
$                         rows=1000000 width=37)
$                        (actual time=0.014..102.907
$                         rows=1000000 loops=1)
$ Total runtime: 637.525 ms
```

PostgreSQL также может сделать сортировку в памяти, но мы должны выделить ей достаточно памяти для использования. Вы можете сделать это с помощью параметра work_mem. По умолчанию он равен 1МБ. Здесь мы устанавливаем его в 200 МБ, а выполняем запрос. PostgreSQL использует алгоритм быстрой сортировки в памяти, и это быстрее (в 9.2 благодаря Петру Geoghegan и его оптимизированной быстрой сортировке).

###33 Индекс также может помочь здесь.

```sql
$ CREATE INDEX ON foo(c1);
$ EXPLAIN (ANALYZE) SELECT * FROM foo ORDER BY c1;
$                      QUERY PLAN
­­$ ­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­-------------------------------------------------­­­­­­­­­­­­­­­­­­­­
$ Index Scan using foo_c1_idx on foo
$    (cost=0.00..34318.35 rows=1000000 width=37)
$    (actual time=0.030..179.810 rows=1000000 loops=1)
$ Total runtime: 214.442 ms
```

Индекс содержит отсортированные данные, так что еще один способ сделать "ORDER BY" это прочитать индекс. В этом примере мы видим, что PostgreSQL предпочитает читать индекс, чем сортировать данные в памяти. И результат еще быстрее: в три раза быстрее.

###34 Давайте вернемся к c2

```sql
$ DROP INDEX foo_c2_idx1;
$ EXPLAIN (ANALYZE,BUFFERS)
$   SELECT * FROM foo WHERE c2 LIKE 'ab%';
$                    QUERY PLAN                                                
­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­$ Seq Scan on foo
$ (cost=0.00..20834.00 rows=100 width=37)
$ (actual time=0.066..134.149 rows=3978 loops=1)
$   Filter: (c2 ~~ 'ab%'::text)
$   Rows Removed by Filter: 996022
$   Buffers: shared hit=8334
$ Total runtime: 134.367 ms
```

Давайте сбросим индекс в колонке С2, и будем использовать EXPLAIN ANALYZE для нового запроса. В этом примере мы хотим получить все строки, которые имеют 'AB' в начале значений ячеек столбца с2. Так как индекса нет, PostgreSQL делает последовательное сканирование и избавляется от 996002 строк.

###35 А теперь, давайте ограничим вывод строк

```sql
$ EXPLAIN (ANALYZE,BUFFERS)
$ SELECT * FROM foo WHERE c2 LIKE 'ab%' LIMIT 10;
$ QUERY PLAN
$ -----------------------------------------------
­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­$ Limit
$ (cost=0.00..2083.40 rows=10 width=37)
$ (actual time=0.065..0.626 rows=10 loops=1)
$   Buffers: shared hit=19
$   -­>  Seq Scan on foo
$       (cost=0.00..20834.00 rows=100 width=37)
$       (actual time=0.063..0.623 rows=10 loops=1)
$         Filter: (c2 ~~ 'ab%'::text)
$         Rows Removed by Filter: 2174
$         Buffers: shared hit=19
$ Total runtime: 0.652 ms
```

С командой LIMIT, мы получаем то же последовательное сканирование, но мы можем заметить, что только избавляемся от 2174 строк. Когда есть LIMIT, это означает, что не нужно получать все строки, а только первые X строк (в данном примере - первые 10 строк). И, таким образом, PostgreSQL должна прочитать 2184 строк для того, чтобы отделить от них десять строк, которые имеют значение в столбце c2, начинающееся с 'AB'.

Она также может работать с использованием индексного сканирования.

###36 Давайте создадим другую таблицу
- Создайте ее

```sql
$ CREATE TABLE bar (c1 integer, c2 boolean);
$ INSERT INTO bar
$   SELECT i, i%2=1
$   FROM generate_series(1, 500000) AS i;
```

- Проанализируйте ее
```sql
$ ANALYZE bar;
```

Нам нужно создать еще одну таблицу, чтобы тестировать JOINs. Мы также вставляем несколько случайных строк в нее, чтобы заполнить таблицу. И, наконец, мы запускаем ANALYZE на нее, чтобы получить статистику.

###37 ... и сделаем join этих двух таблиц

```sql
$ EXPLAIN (ANALYZE)
$ SELECT * FROM foo JOIN bar ON foo.c1=bar.c1;
$                       QUERY PLAN
$ ---------------------------------------------------------
­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­$ Hash Join  (cost=15417.00..63831.00 rows=500000 width=42)
$            (actual time=133.820..766.437 rows=500000 ...)
$   Hash Cond: (foo.c1 = bar.c1)
$   -­>  Seq Scan on foo
$       (cost=0.00..18334.00 rows=1000000 width=37)
$       (actual time=0.009..107.492 rows=1000000 loops=1)
$   -­>  Hash  (cost=7213.00..7213.00 rows=500000 width=5)
$      (actual time=133.166..133.166 rows=500000 loops=1)
$         Buckets: 4096  Batches: 32  Memory Usage: 576kB
$         -­>  Seq Scan on bar
$             (cost=0.00..7213.00 rows=500000 width=5)
$             (actual time=0.011..49.898 rows=500000 loops=1)
$ Total runtime: 782.830 ms
```

Это простой JOIN. Есть несколько способов сделать такого рода объединения и один из них - сделать HashJoin. Идея такого хеширования состоит в том, что хэшируется таблица, а затем хэшируется каждая строка другой таблицы и каждая такая строка сравнивается с первой хешированной таблицей.

В этом примере PostgreSQL делает последовательное сканирование таблицы bar, и вычисляет хэш для каждой из ее строк. Затем делает последовательное сканирование foo, и для каждой строки, вычисляет хэш строки и сравнивает его с хешированной bar-таблицей . Если хеши строк совпадают, строка будет в результирующем наборе. Если хеши строк не совпадает, строка пропускается.

Это хорошо работает при достаточном количестве памяти для хранения хэш таблицы.

###38 Иметь индекс в таблицах - помогает.

```sql
$ CREATE INDEX ON bar(c1);
$ EXPLAIN (ANALYZE)
$ SELECT * FROM foo JOIN bar ON foo.c1=bar.c1;
$                         QUERY PLAN
$ -------------------------------------------------------
­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­$ Merge Join  (cost=0.82..39993.03 rows=500000 width=42)
$       (actual time=0.039..393.172 rows=500000 loops=1)
$   Merge Cond: (foo.c1 = bar.c1)
$   -­>  Index Scan using foo_c1_idx on foo
$       (cost=0.00..34318.35 rows=1000000 width=37)
$       (actual time=0.018..103.613 rows=500001 loops=1)
$   -­>  Index Scan using bar_c1_idx on bar 
$       (cost=0.00..15212.80 rows=500000 width=5)
$       (actual time=0.013..101.863 rows=500000 loops=1)
$ Total runtime: 411.022 ms
```

Если вы добавляете индекс c1 в таблицу bar, то PostgreSQL увидит два индекса.
Данные таблиц сортируются, и появляется хороший способ объединить две таблицы - чтобы объединить два отсортированных набора данных.
С использованием этого нового индекса PostgreSQL может быстро прочитать данные, отсортированные для обеих таблиц, и поэтому PostgreSQL предпочитает делать merge join.

###39 Left join?

```sql
$ EXPLAIN (ANALYZE)
$ SELECT * FROM foo LEFT JOIN bar ON foo.c1=bar.c1;
$ QUERY PLAN
­­$ --------------------------------------------------­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­
$ Merge Left Join
$ (cost=0.82..58281.15 rows=1000000 width=42)
$ (actual time=0.036..540.328 rows=1000000 loops=1)
$   Merge Cond: (foo.c1 = bar.c1)
$   -­>  Index Scan using foo_c1_idx on foo
$       (cost=0.00..34318.35 rows=1000000 width=37)
$       (actual time=0.016..191.645 rows=1000000 loops=1)
$   -­>  Index Scan using bar_c1_idx on bar
$       (cost=0.00..15212.80 rows=500000 width=5)
$       (actual time=0.012..93.921 rows=500000 loops=1)
$ Total runtime: 573.966 ms
$ (5 rows)
```

Этот пример заменяет простой JOIN на LEFT JOIN. Этот результат - Merge Left Join node вместо Merge Join node.

###40 Давайте DROP (сбросим) индекс:

```sql
$ DELETE FROM bar WHERE c1>500; DROP INDEX bar_c1_idx;
$ ANALYZE bar;
$ EXPLAIN (ANALYZE)
$ SELECT * FROM foo JOIN bar ON foo.c1=bar.c1;
$                              QUERY PLAN
$ -----------------------------------------------------­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­
$ Merge Join  (cost=2240.53..2265.26 rows=500 width=42)
$             (actual time=40.433..40.740 rows=500 loops=1)
$   Merge Cond: (foo.c1 = bar.c1)
$   -­>  Index Scan using foo_c1_idx on foo
$       (cost=0.00..34318.35 rows=1000000 width=37)
$       (actual time=0.016..0.130 rows=501 loops=1)
$   -­>  Sort  (cost=2240.41..2241.66 rows=500 width=5)
$       (actual time=40.405..40.432 rows=500 loops=1)
$       Sort Key: bar.c1
$       Sort Method: quicksort  Memory: 48kB
$   -­>  Seq Scan on bar
$       (cost=0.00..2218.00 rows=500 width=5)
$       (actual time=0.020..40.297 rows=500 loops=1)
$ Total runtime: 40.809 ms
```

Чтобы доказать, что Merge Join node нуждается в отсортированных наборах данных, мы сбрасываем индекс в bar, а также удаляем большинство значений bar. Существует немного строк в bar, поэтому сортировка будет быстрой. В этом примере, PostgreSQL решила сделать последовательное сканирование в bar, затем отсортировать данные быстрой сортировкой в памяти. Со сканированием индекса в таблице foo у PostgreSQL есть все, чтобы сделать быстрый Merge Join.


###41 Удаляем некоторое количество строк

```sql
$ DELETE FROM foo WHERE c1>1000;
$ ANALYZE;
$ EXPLAIN (ANALYZE)
$ SELECT * FROM foo JOIN bar ON foo.c1=bar.c1;
$ QUERY PLAN
$ -------------------------------------------------------
­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­$ Nested Loop  (cost=10.79..7413.13 rows=500 width=42)
$              (actual time=0.034..3.287 rows=500 loops=1)
$   -­>  Seq Scan on bar  (cost=0.00..8.00 rows=500 width=5)
$               (actual time=0.006..0.131 rows=500 loops=1)
$   -­>  Bitmap Heap Scan on foo
$       (cost=10.79..14.80 rows=1 width=37)
$       (actual time=0.005..0.005 rows=1 loops=500)
$         Recheck Cond: (c1 = bar.c1)
$         -­>  Bitmap Index Scan on foo_c1_idx
$             (cost=0.00..10.79 rows=1 width=0)
$             (actual time=0.003..0.003 rows=1 loops=500)
$               Index Cond: (c1 = bar.c1)
$ Total runtime: 3.381 ms
```

При удалении большего числа строк, PostgreSQL будет делать вложенный цикл.


###42 А с пустой таблицей?

```sql
$ TRUNCATE bar;
$ ANALYZE;
$ EXPLAIN (ANALYZE)
$ SELECT * FROM foo JOIN bar ON foo.c1>bar.c1;
$                         QUERY PLAN
­­$ -------------------------------------------------­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­
$ Nested Loop
$ (cost=0.00..21405802.11 rows=776666667 width=42)
$ (actual time=0.004..0.004 rows=0 loops=1)
$   -­>  Seq Scan on bar
$       (cost=0.00..33.30 rows=2330 width=5)
$       (actual time=0.002..0.002 rows=0 loops=1)
$   -­>  Index Scan using foo_c1_idx on foo
$       (cost=0.00..5853.70 rows=333333 width=37)
$       (never executed)
$         Index Cond: (c1 > bar.c1)
$ Total runtime: 0.049 ms
```

При отсутствии строк, PostgreSQL еще думает, что имеет несколько строк, но очень небольшой число. Так что она выбирает вложенный цикл. Интересно, что на этот раз это сканирование индекса не самом деле никогда не выполняются, поскольку нет ни одной строки в таблице bar.

###43 Всегда используйте CROSS JOIN

```sql
$ EXPLAIN SELECT * FROM foo CROSS JOIN bar;
$                   QUERY PLAN
$ -----------------------------------------------------
­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­$ Nested Loop
$ (cost=0.00..1641020027.00 rows=100000000000 width=42)
$   -­>  Seq Scan on foo
$       (cost=0.00..18334.00 rows=1000000 width=37)
$   -­>  Materialize
$       (cost=0.00..2334.00 rows=100000 width=5)
$   -­>  Seq Scan on bar
$       (cost=0.00..1443.00 rows=100000 width=5)
```

Вложенный цикл - также kind of node, используемого для CROSS JOIN. CROSS JOIN не может быть использован где-либо еще.

###44 All the join nodes

- Вложенный цикл
 - для небольших таблиц
 - quick to start, slow to finish
- Merge Join
  - сортировка, затем слияние
  - медленный старт без индекса
  - быстрейший на больших объемах данных
- Hash Join
 - только equality join
 - действительно быстрый при достаточном количестве памяти
 - но медленный старт

Теперь, мы видели все join nodes. В PostgreSQL больше нет join nodes. Этих трех доступных достаточно для того, чтобы сделать любой join.

###45 Что насчет отнаследованных таблиц?

- Наша таблица
```sql
$ CREATE TABLE baz(c1 timestamp, c2 text);
```

- Первая отнаследованная таблица, и ее данные:

```sql
$ CREATE TABLE baz_2012(
$   CHECK(c1 BETWEEN '2012­01­01'
$   AND '2012­12­31')
$   ) INHERITS(baz);
$ INSERT INTO baz_2012
$   SELECT now()­i*interval '1 day', 'line '||i
$     FROM generate_series(1, 200) AS i;
```

- Еще две отнаследованные таблицы
 - baz_2011, baz_2010

Inherited tables are mostly used with partitionning, but can also be used in some corner cases. Здесь мы создаем master-таблицу, и три унаследованных (inherited) таблицы. Мы также заполнять их 200 строками каждую.

###46 Давайте сделаем SELECT в baz:

```sql
$ EXPLAIN (ANALYZE) SELECT * FROM baz WHERE c1
$ BETWEEN '2012­06­08' AND '2012­06­10';
$                       QUERY PLAN
­­$ ­­­­­­­­­­­­­­­­­­­­------------------------------------------------­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­
$ Result  (cost=0.00..21.00 rows=11 width=18)
$     -­>  Append  (cost=0.00..21.00 rows=11 width=18)
$           -­>  Seq Scan on baz
$               (cost=0.00..0.00 rows=1 width=40)
$                 Filter: ((c1 >= '2012­06­08...)
$                  AND (c1 <= '2012­06­10...))
$           -­>  Seq Scan on baz_2012 baz
$                (cost=0.00..21.00 rows=10 width=16)
$                  Filter: ((c1 >= '2012­06­08...)
$                      AND (c1 <= '2012­06­10...))
```

- Только один раздел сканируется
 - И мастер таблица

С SELECT нескольких дней 2012 года, мы видим, что PostgreSQL проверяет только master-таблицу и таблицу, связанную с 2012 годом. Другие таблицы не сканируются. Ограничения, доступные для каждой таблицы, гарантируют PostgreSQL, что только bar_2012 содержит данные о 2012. Это будет работать только, если параметр constraint_exclusion включен. Поэтому не отключайте его.

###47 Давайте попробуем с индексом.

```sql
$  CREATE INDEX ON baz_2012(c1);
$  INSERT INTO baz_2012 <a few times>
$  EXPLAIN (ANALYZE) SELECT * FROM baz WHERE c1='2012­06­10';
$                        QUERY PLAN
$ -----------------------------------------------------------
$ ­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­Result  (cost=0.00..8.27 rows=2 width=28)
$         (actual time=0.014..0.014 rows=0 loops=1)
$   -­>  Append  (cost=0.00..8.27 rows=2 width=28)
$                (actual time=0.013..0.013 rows=0 loops=1)
$    -­>  Seq Scan on baz 
$        (cost=0.00..0.00 rows=1 width=40)
$        (actual time=0.002..0.002 rows=0 loops=1)
$         Filter: (c1 = '2012­06­10...)
$    -­>  Index Scan using baz_2012_c1_idx
$                      on baz_2012 baz
$        (cost=0.00..8.27 rows=1 width=16)
$        (actual time=0.011..0.011 rows=0 loops=1)
$          Index Cond: (c1 = '2012­06­10...)
$ Total runtime: 0.052 ms
```

Эта оптимизация также работает с индексом. Она может использовать некоторый специфичный индекс в каждой таблице.

###48 Давайте попробуем aggregate

```sql
   EXPLAIN SELECT count(*) FROM foo;
                QUERY PLAN­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­
  Aggregate
    (cost=20834.00..20834.01 rows=1 width=0)
      -­>  Seq Scan on foo
          (cost=0.00..18334.00 rows=1000000 width=0)
```

Это простейший запрос который у Вас может быть с aggregate и наиболее часто используемый. Есть только один способ сделать это: последовательное сканирование для подсчета всех строк. И вот что PostgreSQL делает с “Aggregate” node.

###49 Попробуем max()

```sql
$  DROP INDEX foo_c2_idx;
$   EXPLAIN (ANALYZE) SELECT max(c2) FROM foo;
$   QUERY PLAN
­­$ ­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­
$   Aggregate
$     (cost=20834.00..20834.01 rows=1 width=33)
$     (actual time=257.813..257.814 rows=1 loops=1)
$    -­>  Seq Scan on foo
$        (cost=0.00..18334.00 rows=1000000 width=33)
$        (actual time=0.011..89.625 rows=1000000 loops=1)
$    Total runtime: 257.856 ms
```
- Некрасиво

max() другая часто используемая функция агрегации. Есть два способа получения максимального значения колонки.

Простейший (и медленный) - прочитать все строки, и взять максимальное значение видимых строк.

###50 Max() лучше с индексом.

```sql
$ CREATE INDEX ON foo(c2);
$ EXPLAIN (ANALYZE) SELECT max(c2) FROM foo;
$ QUERY PLAN
$ ­­­­­­­­­--------------------------------------------------­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­
$ Result
$ (cost=0.08..0.09 rows=1 width=0)
$ (actual time=0.183..0.184 rows=1 loops=1)
$     InitPlan 1 (returns $0)
$       -­>  Limit  (cost=0.00..0.08 rows=1 width=33)
$       (actual time=0.177..0.178 rows=1 loops=1)
$           -­>  Index Only Scan Backward using foo_c2_idx
$                on foo
$               (cost=0.00..79677.29 rows=1000000 width=33)
$               (actual time=0.176..0.176 rows=1 loops=1)
$               Index Cond: (c2 IS NOT NULL)
$              Heap Fetches: 1
$ Total runtime: 0.223 ms
```

- Действительно лучше.

Другой способ заключается в использовании индекса. Индекс имеет уже отсортированые значения, нужно только добраться до большего значения. Это, как правило, подразумевает сканирование индекса (назад, если вы хотите, чтобы большее значение) и ограничить чтение индекса первым значением.

В версии 9.2 “Index Only Scan” может быть использован.

###51 Работает с booleans в 9.2

```sql
$ CREATE INDEX ON foo(c2);
$ EXPLAIN SELECT bool_and(c2) FROM bar;
$ QUERY PLAN
­­$ ­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­---------------------------------------------
$ Result  (cost=0.04..0.05 rows=1 width=0)
$ InitPlan 1 (returns $0)
$     -­>  Limit  (cost=0.00..0.04 rows=1 width=1)
$           -­>  Index Only Scan using bar_c2_idx on bar
$               (cost=0.00..21447.34 rows=500000 width=1)
$                 Index Cond: (c2 IS NOT NULL)
```

Этот вид микро-оптимизации также работает с логическими значениями с версии 9.2. Никогда видел его в продакшне, но она работает :)

###52 Давайте GROUP BY

```sql
$ DROP INDEX foo_c2_idx;
$ EXPLAIN (ANALYZE)
$   SELECT c2, count(*) FROM foo GROUP BY c2;
$                         QUERY PLAN
­­­­­­­­­­­­­­­­­­­­­­­­­$ ----------------------------------------------­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­
$ GroupAggregate
$ (cost=172682.84..190161.00 rows=997816 width=33)
$ (actual time=4444.907..5674.155 rows=999763 loops=1)
$     -­>  Sort
$         (cost=172682.84..175182.84 rows=1000000 width=33)
$         (actual time=4444.893..5368.587 rows=1000000
$          loops=1)
$         Sort Key: c2
$         Sort Method: external merge  Disk: 42080kB
$     -­>  Seq Scan on foo
$        (cost=0.00..18334.00 rows=1000000 width=33)
$        (actual time=0.014..147.936 rows=1000000
$     loops=1)
$ Total runtime: 5715.402 ms
```

Выполнение COUNT(*) для каждого отдельного значения столбца может быть сделано двумя способами. Простой способ - сортировать данные и сгруппировать их в соответствии со значениями.

В этом примере планировщик не имеет никакого индекса для сортировки, поэтому он получает последовательное сканирование, а затем сортировку. Сортировка слишком большая, чтобы происходить в памяти, поэтому используется внешняя сортировка. После сортировки нужно только отсортировать неуникальные значения и посчитать количество. Сортировка здесь занимает много времени (5.3 секунд из 5.6 секунд запроса). Большой размер work_mem может помочь, наличие индекса также.

###52 Наличие большого work_mem помогает

```sql
$ SET work_mem TO '200MB';
$ EXPLAIN (ANALYZE)
$   SELECT c2, count(*) FROM foo GROUP BY c2;
$   QUERY PLAN
$­­ ---------------------------------------------------­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­
$ HashAggregate
$ (actual time=581.653..976.936 rows=999763 loops=1)
$ (cost=23334.00..33312.16 rows=997816 width=33)
$     -­>  Seq Scan on foo
$        (cost=0.00..18334.00 rows=1000000 width=33)
$        (actual time=0.021..96.977 rows=1000000 loops=1)
$ Total runtime: 1019.810 ms
```

С увеличенным work_mem PostgreSQL переключается в HashAggregate так как хеширование может оставаться в памяти.

###54 Или индекс

```sql
$ RESET work_mem;
$ CREATE INDEX ON foo(c2);a
$ EXPLAIN (ANALYZE)
$ SELECT c2, count(*) FROM foo GROUP BY c2;
$ QUERY PLAN
$ --------------------------------------------------­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­
$ GroupAggregate
$ (cost=0.00..92155.45 rows=997816 width=33)
$ (actual time=0.108..1439.023 rows=999763 loops=1)
$       -­>  Index Only Scan using foo_c2_idx on foo
$           (cost=0.00..77177.29 rows=1000000 width=33)
$           (actual time=0.095..1043.090 rows=1000000 loops=1)
$             Heap Fetches: 1000000
$ Total runtime: 1475.775 ms
```

Индекс не помогает с хешированием. Так с индексом и небольшим work_mem возвращаемя к
GroupAggregate. Но в данный момент используется индексное сканировнаие вместо
последовательного, за которым следует сортировка.

###55 Все агрегированные узлы

- Aggregate
- GroupAggregate
- HashAggregate

Все эти агрегированные узлы доступны для планировщика.

###56 Инструменты
- Не так много
 - но несолько полезных
- pgAdmin
- explain.depesz.com
- pg_stat_plans

К сожалению, у нас не так много инструментов, чтобы помочь с планами выполнения. Есть pgAdmin с его графическим изображением плана, explain.depesz.com с его красочными таблицами и pg_stat_plans.

###57 pgAdmin
- Хороший инструмент запросов
- Графический EXPLAIN
- Лучше объясняет первый node, и связь с остальными.
- Большие стрелки означают множество данных

pgAdmin является действительно хорошим инструментом администрирования. Его инструмент запросов имеет множество функций, одной из которых является графический explain. Это, наверное, единственный инструмент администратора с такой особенностью.
Это действительно помогает понять, какой узел сначала должен быть выполнен, и как все они связаны. Размер стрелок имеет смысл: чем больше данных вы получили, тем они больше.

###58 explain.depesz.com
- explain даже лучше, чем explain в графическом pgAdmin
- Вы можете установить его локально
 - One perl module
 - One mojolicious webserver
- Дает вам эклклюзивное время к каждому узлу
 - Лучшая идея для этого инструмента
- Цвета для быстрого определения проблемы в плане

explain.depesz.com замечательный вебсайт, где вы можете запостить план выполнения, полученный из explain.
Самая интересная информация - время выполнения для каждого node. Вы можете делать это руками, но лучше, когда для вас это сделано. Также подсветка помогает вам найти слабые места в вашем explain плане.
Если вы не хотите постить ваш explain план для избежания открытия некоторой конфиденциальной информации, вы также можете
установить ее на одном из ваших серверов. You have one Perl module to install, and a mojolicius
webserver.

###59 explain.depesz.com screenshot

###60 pg_stat_plans
Новое расширение от Peter Geoghegan
- Лучше чем pg_stat_statements
- Позволяет получить план запроса

pg_stat_plans это новое расширение. Написано Peter Geoghegan, from 2ndQuadrant.
Это расширение идет дальше, чем pg_stat_statements потому что оно дает explain план выполняющихся запросов.

###61 Пример pg_stat_plans

```sql
$ SELECT pg_stat_plans_explain(planid, userid, dbid),
$ planid, last_startup_cost, last_total_cost
$ FROM pg_stat_plans
$ WHERE planid = 3002758564;
$ ­[ RECORD 1 ]­­­­­­­­­+­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­
$ pg_stat_plans_explain | GroupAggregate
$ (cost=0.00..92155.45 rows=997816
$   width=33)
$  |   ­>  Index Only Scan
$  using foo_c2_idx
$  on foo
$  (cost=0.00..77177.29
$    rows=1000000
$    width=33)
$    planid                | 3002758564
$    last_startup_cost     | 0
$    last_total_cost       | 92155.450671524
```

В этом примере мы только смотрим план, стимость его старта и общую стоимость.
У вас может быть больше информации такой как had_our_search_path and query_valid.
Почитайте документацию на github: https://github.com/2ndQuadrant/pg_stat_plans

###62 К слову
- If you want to know more about query logging and this new extension
- go see Greg Smith's and Peter Geoghegan's talk
- “Beyond Query Logging”
- Friday, 9:30am to 10:20am
- Room Seine

###63 Заключение
- PostgreSQL планировщик - хорошая штука.
- EXPLAIN дает вам много ключей к разгадке для понимания
 - что делает исполнитель
 - почему он это делает
- С некоторым лучшим пониманием вы, возможно, будуте способны исправить некоторые из ваших вопросов

###64 Вопросы?
- If I don't have time to take any question:
 - I'm here till the end of the event
 - guillaume@lelarge.info
 - But if I have, go ahead :)
